import { Bot, Context } from 'grammy';
import { config } from './config';
import { llmClient } from './llm-client';
import { MemoryManager } from './memory/manager';

// Debounce storage: userId -> { timeout, messages[] }
const pendingMessages = new Map<number, {
    timeout: NodeJS.Timeout;
    messages: string[];
    ctx: Context;
}>();

const memoryManager = new MemoryManager(config.agentId);

async function processMessages(userId: number, messages: string[], ctx: Context): Promise<void> {
    const combinedMessage = messages.join('\n');

    console.log(`ðŸ“¨ Processing ${messages.length} message(s) from user ${userId}`);

    try {
        // Save human message
        await memoryManager.saveMessage(userId, 'HUMAN', combinedMessage);

        // Get memory context
        const memoryContext = await memoryManager.getContextForPrompt(userId);

        // Search documents for RAG
        let ragContext: string | null = null;
        const searchResults = await llmClient.searchDocuments(combinedMessage);

        if (searchResults.length > 0) {
            ragContext = searchResults
                .map((r, i) => `[${i + 1}] ${r.content}`)
                .join('\n\n');
            console.log(`ðŸ“š Found ${searchResults.length} relevant documents`);
        }

        // Build messages with context
        const chatMessages = llmClient.buildMessages(
            config.systemPrompt,
            memoryContext.summary,
            memoryContext.recentMessages,
            ragContext
        );

        // Add current message
        chatMessages.push({ role: 'user', content: combinedMessage });

        // Show typing indicator
        await ctx.replyWithChatAction('typing');

        // Get response
        const response = await llmClient.chat(chatMessages);

        // Save AI message
        await memoryManager.saveMessage(userId, 'AI', response);

        // Send response
        await ctx.reply(response, {
            parse_mode: 'Markdown',
        }).catch(async () => {
            // If markdown fails, send as plain text
            await ctx.reply(response);
        });

    } catch (error: any) {
        console.error('Error processing message:', error.message);
        await ctx.reply('âš ï¸ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.');
    }
}

function scheduleProcessing(userId: number, message: string, ctx: Context): void {
    const existing = pendingMessages.get(userId);

    if (existing) {
        // Clear existing timeout and add message
        clearTimeout(existing.timeout);
        existing.messages.push(message);
        existing.ctx = ctx; // Update context to latest
    } else {
        pendingMessages.set(userId, {
            timeout: null as any,
            messages: [message],
            ctx,
        });
    }

    // Set new timeout
    const pending = pendingMessages.get(userId)!;
    pending.timeout = setTimeout(async () => {
        const data = pendingMessages.get(userId);
        if (data) {
            pendingMessages.delete(userId);
            await processMessages(userId, data.messages, data.ctx);
        }
    }, config.debounceMs);
}

export function createBot(): Bot<Context> {
    const bot = new Bot(config.telegramBotToken);

    // Start command
    bot.command('start', async (ctx) => {
        const welcomeMessage = `ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ ${config.agentName}.

Ð¯ Ð³Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ‚ÐµÐ±Ðµ. ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ Ð¼Ð½Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, Ð¸ Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ!

â±ï¸ Ð¯ Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ñƒ ${config.debounceMs / 1000} ÑÐµÐºÑƒÐ½Ð´ Ð¿Ð¾ÑÐ»Ðµ Ñ‚Ð²Ð¾ÐµÐ³Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ‚Ñ‹ Ð¼Ð¾Ð³ Ð´Ð¾Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð¼Ñ‹ÑÐ»ÑŒ.

/clear - Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
/help - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ`;

        await ctx.reply(welcomeMessage);
    });

    // Help command
    bot.command('help', async (ctx) => {
        await ctx.reply(`ðŸ¤– ${config.agentName}

Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:
/start - Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³
/clear - Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
/help - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ñƒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ

ðŸ’¡ Ð¯ Ð¶Ð´Ñƒ ${config.debounceMs / 1000} ÑÐµÐº. Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ, Ð¿Ñ€ÐµÐ¶Ð´Ðµ Ñ‡ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ.
Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ñ‚ÐµÐ±Ðµ Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¿Ð¾Ð´Ñ€ÑÐ´.`);
    });

    // Clear conversation history
    bot.command('clear', async (ctx) => {
        const userId = ctx.from?.id;
        if (userId) {
            await memoryManager.clearHistory(userId);
        }
        await ctx.reply('ðŸ—‘ï¸ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°.');
    });

    // Handle text messages with debounce
    bot.on('message:text', async (ctx) => {
        const userId = ctx.from?.id;
        const userMessage = ctx.message.text;

        if (!userId) return;

        // Schedule message processing with debounce
        scheduleProcessing(userId, userMessage, ctx);

        console.log(`ðŸ“ Message queued from user ${userId}, waiting ${config.debounceMs}ms...`);
    });

    // Handle errors
    bot.catch((err) => {
        console.error('Bot error:', err);
    });

    return bot;
}
